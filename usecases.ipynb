{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50631a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/15 13:30:11 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "import pandas as pd\n",
    "from pyspark.sql.functions import col\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea929294",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/15 13:30:21 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    }
   ],
   "source": [
    "reviews = spark.read.format('json').load('/Users/sharanyu/Documents/yelp compressed/yelp_academic_dataset_review.json')\n",
    "users = spark.read.format('json').load('/Users/sharanyu/Documents/yelp compressed/yelp_academic_dataset_user.json')\n",
    "checkin = spark.read.format('json').load('/Users/sharanyu/Documents/yelp compressed/yelp_academic_dataset_checkin.json')\n",
    "tip = spark.read.format('json').load('/Users/sharanyu/Documents/yelp compressed/yelp_academic_dataset_tip.json')\n",
    "business = spark.read.format('json').load('/Users/sharanyu/Documents/yelp compressed/yelp_academic_dataset_business.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f90fdcc",
   "metadata": {},
   "source": [
    "## Usecase1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4c79e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def usecase1(users,reviews,business):\n",
    "    df = users.join(reviews, reviews.user_id == users.user_id)\n",
    "\n",
    "    df = df.join(business, business.business_id == reviews.business_id)\n",
    "\n",
    "    df = df.where(df.categories.contains(\"Restaurants\"))\n",
    "\n",
    "    df = df.withColumn(\"WiFi\", F.col(\"attributes.WiFi\")).withColumn(\"WheelChairAccessible\",F.col(\"attributes.WheelchairAccessible\"))\n",
    "\n",
    "    df_query = df.select(business.name,business.city,business.state,df.average_stars,df.WiFi,df.WheelChairAccessible)\n",
    "\n",
    "    df_query = df_query.filter((df_query.average_stars > 4.0) & (df_query.WiFi.contains('free')) & (df_query.WheelChairAccessible.contains('True')))\n",
    "    \n",
    "    df_query.count()\n",
    "    \n",
    "    return df_query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e039cc",
   "metadata": {},
   "source": [
    "## Usecase2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31dd24b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def usecase2(users,reviews,business):\n",
    "    df = users.join(reviews, reviews.user_id == users.user_id)\n",
    "\n",
    "    df = df.join(business, business.business_id == reviews.business_id)\n",
    "    \n",
    "    df = df.where((df.categories.contains(\"Gas Stations\")) & (df.categories.contains('Food')) | (df.categories.contains('Fast Food')) | (df.categories.contains('Restaurants')) | (df.categories.contains('Pizza')))\n",
    "    \n",
    "    df_query = df.filter((df.average_stars > 3.5) & (df.state==\"FL\"))\n",
    "    \n",
    "    df_query = df_query.select(business.name,df_query.average_stars,df_query.hours,df_query.city,df_query.postal_code)\n",
    "    \n",
    "    df_queryfinal = df_query.withColumn('Friday',F.col('hours.Friday')).withColumn('Saturday',F.col('hours.Saturday')).withColumn('Sunday',F.col('hours.Sunday'))\n",
    "    \n",
    "    df_queryfinal=df_queryfinal.drop('hours')\n",
    "    \n",
    "    df_queryfinal.count()\n",
    "    \n",
    "    return df_queryfinal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c941d33",
   "metadata": {},
   "source": [
    "## Usecase3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd4986a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def usecase3(users,reviews,business):\n",
    "    df = users.join(reviews, reviews.user_id == users.user_id)\n",
    "\n",
    "    df = df.join(business, business.business_id == reviews.business_id)\n",
    "    \n",
    "    df = df.filter(df.elite != '')\n",
    "    \n",
    "    def complimentsum(a,b,c,d,e,f,g,h,i,j,k):\n",
    "        col_sum = a+b+c+d+e+f+g+h+i+k\n",
    "        return col_sum\n",
    "    \n",
    "    new_f = F.udf(complimentsum, IntegerType())\n",
    "    \n",
    "    df_usercomp = df.withColumn(\"total_compliments\",\n",
    "                              new_f(\"compliment_hot\", \"compliment_more\", \"compliment_profile\",\"compliment_cute\",\"compliment_list\",\"compliment_note\",\"compliment_plain\",\"compliment_cool\",\"compliment_funny\",\"compliment_writer\",\"compliment_photos\"))\n",
    "    \n",
    "    df_usercomp = df_usercomp.filter((df_usercomp.fans > 100) | (users.review_count > 500) | (df_usercomp.total_compliments > 1000))\n",
    "    \n",
    "    df_usercomp = df_usercomp.filter(df_usercomp.average_stars > 4.0)\n",
    "    \n",
    "    df_usercomp = df_usercomp.select(business.name,business.review_count,business.categories,business.city,business.state)\n",
    "    \n",
    "    df_usercomp.count()\n",
    "    \n",
    "    return df_usercomp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed148f9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# calling usecase 1\n",
    "\n",
    "restaurants_whlchraccess_wifi = usecase1(users,reviews,business)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e655f11d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# calling usecase 2\n",
    "\n",
    "business_gasstation_weeknds = usecase2(users,reviews,business)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48d03c64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# calling usecase 3\n",
    "\n",
    "certified_businesses = usecase3(users,reviews,business)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
